{
  "source_file_path_relative_to_docusaurus_root": "blog/2021-12-10-implement-chaos-engineering-in-k8s.md",
  "source_file_content_hash": "ae13e1a4f80105f1621a2eb77d731ffca386b1bfcbe31124119923e2a7d4be3b",
  "segments": [
    {
      "segment_id": "58cfcc64",
      "source_content": "---\nslug: /implement-chaos-engineering-in-k8s\ntitle: 'Implementing Chaos Engineering in K8s: Chaos Mesh Principle Analysis and Control Plane Development'\nauthors: mayocream\nimage: /img/blog/implement-chaos-engineering-in-k8s.png\ntags: [Chaos Mesh, Chaos Engineering]\n---",
      "source_content_hash": "ffb4cf38d7d244336988683361eca0dac15df5aff9dfc4ad6c693666049221aa",
      "node_type": "yaml",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_58cfcc64"
      }
    },
    {
      "segment_id": "53eaf0e1",
      "source_content": "![Implementing Chaos Engineering in K8s](/img/blog/implement-chaos-engineering-in-k8s.png)",
      "source_content_hash": "4c78a17be7d6583f328714aa74fdbbd7decd429442df06605ce361ec246804ef",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "![Kubernetesにおけるカオスエンジニアリングの実装](/img/blog/implement-chaos-engineering-in-k8s.png)"
      }
    },
    {
      "segment_id": "8ac585fb",
      "source_content": "[Chaos Mesh](https://chaos-mesh.org/docs/) is an open-source, cloud-native Chaos Engineering platform built on Kubernetes (K8s) custom resource definitions (CRDs). Chaos Mesh can simulate various types of faults and has an enormous capability to orchestrate fault scenarios. You can use Chaos Mesh to conveniently simulate various abnormalities that might occur in development, testing, and production environments and find potential problems in the system.",
      "source_content_hash": "849e8cba0f0c43d2468211c55a0bbc13c3b4768b3b95e8b163a9f020029488cd",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "[Chaos Mesh](https://chaos-mesh.org/docs/)は、Kubernetes（K8s）のカスタムリソース定義（CRD）上に構築されたオープンソースのクラウドネイティブなカオスエンジニアリングプラットフォームです。Chaos Meshはさまざまな種類の障害をシミュレートでき、障害シナリオをオーケストレーションする巨大な能力を持っています。開発、テスト、本番環境で発生する可能性のあるさまざまな異常を簡単にシミュレートし、システム内の潜在的な問題を見つけることができます。"
      }
    },
    {
      "segment_id": "3e6699f4",
      "source_content": "<!--truncate-->",
      "source_content_hash": "f5cded2aa7e288e395fe4f67f9dabda2281904b2f5358d07302b3aa8be0acdfa",
      "node_type": "comment",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_3e6699f4"
      }
    },
    {
      "segment_id": "cf898102",
      "source_content": "In this article, I'll explore the practice of Chaos Engineering in Kubernetes clusters, discuss important Chaos Mesh features through analysis of its source code, and explain how to develop Chaos Mesh's control plane with code examples.",
      "source_content_hash": "0a17aac24b5ea7ca73860c41633007e668a1cd45b7319d3db06833f944de589a",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "この記事では、Kubernetesクラスターにおけるカオスエンジニアリングの実践を探り、ソースコードの分析を通じてChaos Meshの重要な機能について議論し、コード例を用いてChaos Meshのコントロールプレーンの開発方法を説明します。"
      }
    },
    {
      "segment_id": "42ad8e83",
      "source_content": "If you're not familiar with Chaos Mesh, please review the [Chaos Mesh documentation](https://chaos-mesh.org/docs/#architecture-overview) to get a basic knowledge of Chaos Mesh's architecture.",
      "source_content_hash": "f24f02a91498395f95006172e32db89db15fa5eac2bb785647c823f7a58914f6",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Chaos Meshに慣れていない場合は、[Chaos Meshのドキュメント](https://chaos-mesh.org/docs/#architecture-overview)を確認して、Chaos Meshのアーキテクチャに関する基本的な知識を取得してください。"
      }
    },
    {
      "segment_id": "f6168993",
      "source_content": "For the test code in this article, see the [mayocream/chaos-mesh-controlpanel-demo](https://github.com/mayocream/chaos-mesh-controlpanel-demo) repository on GitHub.",
      "source_content_hash": "82683b3f6c1840e7151189286fb3aff5b54cacf0d7e405c2ba82f8483e560d89",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "この記事のテストコードについては、GitHubの[mayocream/chaos-mesh-controlpanel-demo](https://github.com/mayocream/chaos-mesh-controlpanel-demo)リポジトリを参照してください。"
      }
    },
    {
      "segment_id": "418617bd",
      "source_content": "## How Chaos Mesh creates chaos",
      "source_content_hash": "be08c013ab87f284b3bb2c017f4677d7477f634260e257efed6df4bc01d63b0b",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "## Chaos Meshがカオスを生み出す方法"
      }
    },
    {
      "segment_id": "2fdadb08",
      "source_content": "Chaos Mesh is a Swiss army knife for implementing Chaos Engineering on Kubernetes. This section introduces how it works.",
      "source_content_hash": "e78701f7e79d05ae8aa3f3f76f1f65f0d119ccf83ab04917a057aa7c07b70ab4",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Chaos Meshは、Kubernetes上でカオスエンジニアリングを実装するためのスイスアーミーナイフです。このセクションでは、その仕組みを紹介します。"
      }
    },
    {
      "segment_id": "ed7dde9c",
      "source_content": "### Privileged mode",
      "source_content_hash": "ec7bc259662e4dc003a5e0e69de4ba3fae62805d490e9409a37aac2aebfda9b9",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "### 特権モード"
      }
    },
    {
      "segment_id": "a76548f8",
      "source_content": "Chaos Mesh runs privileged containers in Kubernetes to create failures. Chaos Daemon's Pod runs as `DaemonSet` and adds additional [capabilities](https://kubernetes.io/docs/concepts/policy/pod-security-policy/#capabilities) to the Pod's container runtime via the Pod's security context.",
      "source_content_hash": "0457d066f8bec94acb32c96f086a70c21f31c64ebd4ddedf13a3d27baf66d82d",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Chaos Meshは、Kubernetesで特権コンテナを実行して障害を作り出します。Chaos DaemonのPodは`DaemonSet`として実行され、Podのセキュリティコンテキストを介してPodのコンテナランタイムに追加の[capabilities](https://kubernetes.io/docs/concepts/policy/pod-security-policy/#capabilities)を追加します。"
      }
    },
    {
      "segment_id": "0c911872",
      "source_content": "```yaml\napiVersion: apps/v1\nkind: DaemonSet\nspec:\n template:\n   metadata: ...\n   spec:\n     containers:\n       - name: chaos-daemon\n         securityContext:\n           {{- if .Values.chaosDaemon.privileged }}\n           privileged: true\n           capabilities:\n             add:\n               - SYS_PTRACE\n           {{- else }}\n           capabilities:\n             add:\n               - SYS_PTRACE\n               - NET_ADMIN\n               - MKNOD\n               - SYS_CHROOT\n               - SYS_ADMIN\n               - KILL\n               # CAP_IPC_LOCK is used to lock memory\n               - IPC_LOCK\n           {{- end }}\n```",
      "source_content_hash": "2cdc696bd2be1ea07087ad1f038ea6e5e13b3df4aa8d733a1f198a26c23c3e52",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_0c911872"
      }
    },
    {
      "segment_id": "e536ea0d",
      "source_content": "The Linux capabilities grant containers privileges to create and access the `/dev/fuse` Filesystem in Userspace (FUSE) pipe. FUSE is the Linux userspace filesystem interface. It lets non-privileged users create their own file systems without editing the kernel code.",
      "source_content_hash": "8064f6020422976357f3e8290c43eb82fd54cb7489c78b739e446c9fee8360b5",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Linuxのcapabilitiesは、コンテナに`/dev/fuse` Filesystem in Userspace（FUSE）パイプを作成およびアクセスする特権を付与します。FUSEはLinuxのユーザースペースファイルシステムインターフェースです。これにより、非特権ユーザーがカーネルコードを編集することなく独自のファイルシステムを作成できます。"
      }
    },
    {
      "segment_id": "40158b4b",
      "source_content": "According to [pull request #1109](https://github.com/chaos-mesh/chaos-mesh/pull/1109) on GitHub, the `DaemonSet` program uses cgo to call the Linux `makedev` function to create a FUSE pipe.",
      "source_content_hash": "c024b7c17b157dacdf8f62f7d1454f4cdb9705f31b192472b39da290aa859f9e",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "GitHubの[プルリクエスト #1109](https://github.com/chaos-mesh/chaos-mesh/pull/1109)によると、`DaemonSet`プログラムはcgoを使用してLinuxの`makedev`関数を呼び出し、FUSEパイプを作成します。"
      }
    },
    {
      "segment_id": "3adc0ceb",
      "source_content": "```go\n// #include <sys/sysmacros.h>\n// #include <sys/types.h>\n// // makedev is a macro, so a wrapper is needed\n// dev_t Makedev(unsigned int maj, unsigned int min) {\n//   return makedev(maj, min);\n// }\n// EnsureFuseDev ensures /dev/fuse exists. If not, it will create one\n\nfunc EnsureFuseDev() {\n   if _, err := os.Open(\"/dev/fuse\"); os.IsNotExist(err) {\n       // 10, 229 according to https://www.kernel.org/doc/Documentation/admin-guide/devices.txt\n       fuse := C.Makedev(10, 229)\n       syscall.Mknod(\"/dev/fuse\", 0o666|syscall.S_IFCHR, int(fuse))\n   }\n}\n```",
      "source_content_hash": "35d795dd08e3d09acfb34f709998152dde0c0a857461f0f80364ac6eda6c250a",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_3adc0ceb"
      }
    },
    {
      "segment_id": "7736989b",
      "source_content": "In [pull request #1453](https://github.com/chaos-mesh/chaos-mesh/pull/1453), Chaos Daemon enables privileged mode by default; that is, it sets `privileged: true` in the container's `SecurityContext`.",
      "source_content_hash": "13b2cb088a1d27048ef7a1a3eda7bb523c1fe8535ba16c2e15465e6aa083b3b7",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "[プルリクエスト #1453](https://github.com/chaos-mesh/chaos-mesh/pull/1453)では、Chaos Daemonはデフォルトで特権モードを有効にしています。つまり、コンテナの`SecurityContext`に`privileged: true`を設定しています。"
      }
    },
    {
      "segment_id": "8a9b6c26",
      "source_content": "### Killing Pods",
      "source_content_hash": "9650e900c10b6e388917ef87ad66c4da23207c7982b7c93be6c0503f71d2e0ce",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "### Podの強制終了"
      }
    },
    {
      "segment_id": "a1fa5396",
      "source_content": "`PodKill`, `PodFailure`, and `ContainerKill` belong to the `PodChaos` category. `PodKill` randomly kills a Pod. It calls the API server to send the kill command.",
      "source_content_hash": "a911e538c0d5a6024b44fe74b7001c6013926198d675da968b39ec803cbfe47a",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "`PodKill`、`PodFailure`、`ContainerKill`は`PodChaos`カテゴリに属します。`PodKill`はランダムにPodを強制終了します。APIサーバーを呼び出して強制終了コマンドを送信します。"
      }
    },
    {
      "segment_id": "8c3563d3",
      "source_content": "```go\nimport (\n   \"context\"\n   v1 \"k8s.io/api/core/v1\"\n   \"sigs.k8s.io/controller-runtime/pkg/client\"\n)\n\ntype Impl struct {\n   client.Client\n}\n\nfunc (impl *Impl) Apply(ctx context.Context, index int, records []*v1alpha1.Record, obj v1alpha1.InnerObject) (v1alpha1.Phase, error) {\n   ...\n   err = impl.Get(ctx, namespacedName, &pod)\n   if err != nil {\n       // TODO: handle this error\n       return v1alpha1.NotInjected, err\n   }\n   err = impl.Delete(ctx, &pod, &client.DeleteOptions{\n       GracePeriodSeconds: &podchaos.Spec.GracePeriod, // PeriodSeconds has to be set specifically\n   })\n   ...\n   return v1alpha1.Injected, nil\n}\n```",
      "source_content_hash": "a6d31ce49af2c82114aee32ceb58fe02d4efa9f8b5894f6e7905388b81241874",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_8c3563d3"
      }
    },
    {
      "segment_id": "0801d969",
      "source_content": "The `GracePeriodSeconds` parameter lets Kubernetes [forcibly terminate a Pod](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination-forced). For example, if you need to delete a Pod immediately, use the `kubectl delete pod --grace-period=0 --force` command.",
      "source_content_hash": "c73c37ed4820909f41e11d24673cc47fe409861fe13c7177ec766943e0a911b5",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "`GracePeriodSeconds`パラメータを使用すると、Kubernetesは[Podを強制的に終了](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination-forced)できます。たとえば、Podを即座に削除する必要がある場合は、`kubectl delete pod --grace-period=0 --force`コマンドを使用します。"
      }
    },
    {
      "segment_id": "3c19e221",
      "source_content": "`PodFailure` patches the Pod object resource to replace the image in the Pod with a wrong one. Chaos only modifies the `image` fields of `containers` and `initContainers`. This is because most of the metadata about a Pod is immutable. For more details, see [Pod update and replacement](https://kubernetes.io/docs/concepts/workloads/pods/#pod-update-and-replacement).",
      "source_content_hash": "f85e5161fbcc0f6cf9062d3a2a7418735fd421c9b528668e7e79c190261648ce",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "`PodFailure`はPodオブジェクトリソースにパッチを適用し、Pod内のイメージを誤ったものに置き換えます。Chaosは`containers`と`initContainers`の`image`フィールドのみを変更します。これは、Podに関するメタデータの大部分が不変であるためです。詳細については、[Podの更新と置換](https://kubernetes.io/docs/concepts/workloads/pods/#pod-update-and-replacement)を参照してください。"
      }
    },
    {
      "segment_id": "f155ef1e",
      "source_content": "```go\nfunc (impl *Impl) Apply(ctx context.Context, index int, records []*v1alpha1.Record, obj v1alpha1.InnerObject) (v1alpha1.Phase, error) {\n   ...\n   pod := origin.DeepCopy()\n   for index := range pod.Spec.Containers {\n       originImage := pod.Spec.Containers[index].Image\n       name := pod.Spec.Containers[index].Name\n       key := annotation.GenKeyForImage(podchaos, name, false)\n       if pod.Annotations == nil {\n           pod.Annotations = make(map[string]string)\n       }\n       // If the annotation is already existed, we could skip the reconcile for this container\n       if _, ok := pod.Annotations[key]; ok {\n           continue\n       }\n       pod.Annotations[key] = originImage\n       pod.Spec.Containers[index].Image = config.ControllerCfg.PodFailurePauseImage\n   }\n   for index := range pod.Spec.InitContainers {\n       originImage := pod.Spec.InitContainers[index].Image\n       name := pod.Spec.InitContainers[index].Name\n       key := annotation.GenKeyForImage(podchaos, name, true)\n       if pod.Annotations == nil {\n           pod.Annotations = make(map[string]string)\n       }\n       // If the annotation is already existed, we could skip the reconcile for this container\n       if _, ok := pod.Annotations[key]; ok {\n           continue\n       }\n       pod.Annotations[key] = originImage\n       pod.Spec.InitContainers[index].Image = config.ControllerCfg.PodFailurePauseImage\n   }\n   err = impl.Patch(ctx, pod, client.MergeFrom(&origin))\n   if err != nil {\n       // TODO: handle this error\n       return v1alpha1.NotInjected, err\n   }\n   return v1alpha1.Injected, nil\n}\n```",
      "source_content_hash": "ea8fe9c66aa5fc2f132a6528a17e1a946267c6d24e7f7c571247a4c9abb115ab",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_f155ef1e"
      }
    },
    {
      "segment_id": "63565425",
      "source_content": "The default container image that causes failures is `gcr.io/google-containers/pause:latest`.",
      "source_content_hash": "e0cb31b572567ec072479496cbc688b50a271ff1fb3f3b3e674d1c048bb24ff4",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "障害を引き起こすデフォルトのコンテナイメージは`gcr.io/google-containers/pause:latest`です。"
      }
    },
    {
      "segment_id": "1496ef51",
      "source_content": "`PodKill` and `PodFailure` control the Pod lifecycle through the Kubernetes API server. But `ContainerKill` does this through Chaos Daemon that runs on the cluster node. `ContainerKill` uses Chaos Controller Manager to run the client to initiate gRPC calls to Chaos Daemon.",
      "source_content_hash": "bdc4416d18f525e1997615527f37abe3ccf985f8ec97ba8d99708e75f9c9e787",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "`PodKill`と`PodFailure`はKubernetes APIサーバーを介してPodのライフサイクルを制御します。しかし、`ContainerKill`はクラスターノード上で実行されるChaos Daemonを介してこれを行います。`ContainerKill`はChaos Controller Managerを使用してクライアントを実行し、Chaos DaemonへのgRPC呼び出しを開始します。"
      }
    },
    {
      "segment_id": "b68d496b",
      "source_content": "```go\nfunc (b *ChaosDaemonClientBuilder) Build(ctx context.Context, pod *v1.Pod) (chaosdaemonclient.ChaosDaemonClientInterface, error) {\n   ...\n   daemonIP, err := b.FindDaemonIP(ctx, pod)\n   if err != nil {\n       return nil, err\n   }\n   builder := grpcUtils.Builder(daemonIP, config.ControllerCfg.ChaosDaemonPort).WithDefaultTimeout()\n   if config.ControllerCfg.TLSConfig.ChaosMeshCACert != \"\" {\n       builder.TLSFromFile(config.ControllerCfg.TLSConfig.ChaosMeshCACert, config.ControllerCfg.TLSConfig.ChaosDaemonClientCert, config.ControllerCfg.TLSConfig.ChaosDaemonClientKey)\n   } else {\n       builder.Insecure()\n   }\n   cc, err := builder.Build()\n   if err != nil {\n       return nil, err\n   }\n   return chaosdaemonclient.New(cc), nil\n}\n```",
      "source_content_hash": "5c7c88d59f634ed798ba5f85f29f1890d099add0a9b06fe77ec764b6dac8870c",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_b68d496b"
      }
    },
    {
      "segment_id": "9ef42155",
      "source_content": "When Chaos Controller Manager sends commands to Chaos Daemon, it creates a corresponding client based on the Pod information. For example, to control a Pod on a node, it creates a client by getting the `ClusterIP` of the node where the Pod is located. If the Transport Layer Security (TLS) certificate configuration exists, Controller Manager adds the TLS certificate for the client.",
      "source_content_hash": "18e9d14543b6ba6b6f743b7cdbbeddf70070f410330cb5c836880fe634e149ca",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Chaos Controller ManagerがChaos Daemonにコマンドを送信する際、Pod情報に基づいて対応するクライアントを作成します。例えば、ノード上のPodを制御する場合、Podが配置されているノードの`ClusterIP`を取得してクライアントを作成します。Transport Layer Security（TLS）証明書の設定が存在する場合、Controller ManagerはクライアントにTLS証明書を追加します。"
      }
    },
    {
      "segment_id": "fe25bd72",
      "source_content": "When Chaos Daemon starts, if it has a TLS certificate it attaches the certificate to enable gRPCS. The TLS configuration option `RequireAndVerifyClientCert` indicates whether to enable mutual TLS (mTLS) authentication.",
      "source_content_hash": "d58a6618e0d89ae1ce8aad2e578679a0e11aff577861d7f0498c9729dac30c4b",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Chaos Daemon起動時、TLS証明書を持っている場合、gRPCSを有効化するために証明書を添付します。TLS設定オプション`RequireAndVerifyClientCert`は相互TLS（mTLS）認証を有効にするかどうかを示します。"
      }
    },
    {
      "segment_id": "65ba7468",
      "source_content": "```go\nfunc newGRPCServer(containerRuntime string, reg prometheus.Registerer, tlsConf tlsConfig) (*grpc.Server, error) {\n   ...\n   if tlsConf != (tlsConfig{}) {\n       caCert, err := ioutil.ReadFile(tlsConf.CaCert)\n       if err != nil {\n           return nil, err\n       }\n       caCertPool := x509.NewCertPool()\n       caCertPool.AppendCertsFromPEM(caCert)\n       serverCert, err := tls.LoadX509KeyPair(tlsConf.Cert, tlsConf.Key)\n       if err != nil {\n           return nil, err\n       }\n       creds := credentials.NewTLS(&tls.Config{\n           Certificates: []tls.Certificate{serverCert},\n           ClientCAs:    caCertPool,\n           ClientAuth:   tls.RequireAndVerifyClientCert,\n       })\n       grpcOpts = append(grpcOpts, grpc.Creds(creds))\n   }\n   s := grpc.NewServer(grpcOpts...)\n   grpcMetrics.InitializeMetrics(s)\n   pb.RegisterChaosDaemonServer(s, ds)\n   reflection.Register(s)\n   return s, nil\n}\n```",
      "source_content_hash": "721a3652e6d43bd4ab3bcb1be02c1dc5f2d7218b302a7e4e92d078530826ed98",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_65ba7468"
      }
    },
    {
      "segment_id": "af834e0d",
      "source_content": "Chaos Daemon provides the following gRPC interfaces to call:",
      "source_content_hash": "310786593645bb24b2d855c132001014278139c8cd6ee89bb83b09e15238b1d2",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Chaos Daemonは呼び出し可能な以下のgRPCインターフェースを提供します："
      }
    },
    {
      "segment_id": "6b0761da",
      "source_content": "```go\n// ChaosDaemonClient is the client API for ChaosDaemon service.\n//\n// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.\n\ntype ChaosDaemonClient interface {\n\n   SetTcs(ctx context.Context, in *TcsRequest, opts ...grpc.CallOption) (*empty.Empty, error)\n   FlushIPSets(ctx context.Context, in *IPSetsRequest, opts ...grpc.CallOption) (*empty.Empty, error)\n   SetIptablesChains(ctx context.Context, in *IptablesChainsRequest, opts ...grpc.CallOption) (*empty.Empty, error)\n   SetTimeOffset(ctx context.Context, in *TimeRequest, opts ...grpc.CallOption) (*empty.Empty, error)\n   RecoverTimeOffset(ctx context.Context, in *TimeRequest, opts ...grpc.CallOption) (*empty.Empty, error)\n   ContainerKill(ctx context.Context, in *ContainerRequest, opts ...grpc.CallOption) (*empty.Empty, error)\n   ContainerGetPid(ctx context.Context, in *ContainerRequest, opts ...grpc.CallOption) (*ContainerResponse, error)\n   ExecStressors(ctx context.Context, in *ExecStressRequest, opts ...grpc.CallOption) (*ExecStressResponse, error)\n   CancelStressors(ctx context.Context, in *CancelStressRequest, opts ...grpc.CallOption) (*empty.Empty, error)\n   ApplyIOChaos(ctx context.Context, in *ApplyIOChaosRequest, opts ...grpc.CallOption) (*ApplyIOChaosResponse, error)\n   ApplyHttpChaos(ctx context.Context, in *ApplyHttpChaosRequest, opts ...grpc.CallOption) (*ApplyHttpChaosResponse, error)\n   SetDNSServer(ctx context.Context, in *SetDNSServerRequest, opts ...grpc.CallOption) (*empty.Empty, error)\n}\n```",
      "source_content_hash": "4f577c03ed64b33b02847235f404a44b30d9ad8fa491d87baede4e619995397f",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_6b0761da"
      }
    },
    {
      "segment_id": "7eac7922",
      "source_content": "### Network failure injection",
      "source_content_hash": "2aa0302dd78c12c659d251d65efbf6ce112ffee194fa9f3243d770f9b32bdb2b",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "### ネットワーク障害の注入"
      }
    },
    {
      "segment_id": "8f4e752e",
      "source_content": "From [pull request #41](https://github.com/chaos-mesh/chaos-mesh/pull/41), we know that Chaos Mesh injects network failures this way: it calls `pbClient.SetNetem` to encapsulate parameters into a request and send the request to the Chaos Daemon on the node for processing.",
      "source_content_hash": "3f19b793141466d5a8aa5dba3934b804d15323ae43f316c3f7375b86c30cadc3",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "[プルリクエスト #41](https://github.com/chaos-mesh/chaos-mesh/pull/41)から、Chaos Meshがネットワーク障害を注入する方法がわかります：`pbClient.SetNetem`を呼び出してパラメータをリクエストにカプセル化し、そのリクエストをノード上のChaos Daemonに送信して処理させます。"
      }
    },
    {
      "segment_id": "f211c69a",
      "source_content": "The network failure injection code is shown below as it appeared in 2019. As the project developed, the functions were distributed among several files.",
      "source_content_hash": "9cdcf93fcc0aee4d262006dac5417455cfac4903095c003fa70d57fa60438a63",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "2019年時点でのネットワーク障害注入コードを以下に示します。プロジェクトの進化に伴い、機能は複数のファイルに分散されました。"
      }
    },
    {
      "segment_id": "03859cae",
      "source_content": "```go\nfunc (r *Reconciler) applyPod(ctx context.Context, pod *v1.Pod, networkchaos *v1alpha1.NetworkChaos) error {\n   ...\n   pbClient := pb.NewChaosDaemonClient(c)\n   containerId := pod.Status.ContainerStatuses[0].ContainerID\n   netem, err := spec.ToNetem()\n   if err != nil {\n       return err\n   }\n   _, err = pbClient.SetNetem(ctx, &pb.NetemRequest{\n       ContainerId: containerId,\n       Netem:       netem,\n   })\n   return err\n}\n```",
      "source_content_hash": "6febb71cfad953d8f50eed50f3ddcd9b595fcb8b803b8f1148144f5f2134a444",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_03859cae"
      }
    },
    {
      "segment_id": "9c70c953",
      "source_content": "In the `pkg/chaosdaemon` package, we can see how Chaos Daemon processes requests.",
      "source_content_hash": "cd0afd3c76f8d216177bfa1431efb49a21ebc312c9da17887044b31bc880d6e4",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "`pkg/chaosdaemon`パッケージでは、Chaos Daemonがリクエストを処理する方法を確認できます。"
      }
    },
    {
      "segment_id": "d5f63a23",
      "source_content": "```go\nfunc (s *Server) SetNetem(ctx context.Context, in *pb.NetemRequest) (*empty.Empty, error) {\n   log.Info(\"Set netem\", \"Request\", in)\n   pid, err := s.crClient.GetPidFromContainerID(ctx, in.ContainerId)\n   if err != nil {\n       return nil, status.Errorf(codes.Internal, \"get pid from containerID error: %v\", err)\n   }\n   if err := Apply(in.Netem, pid); err != nil {\n       return nil, status.Errorf(codes.Internal, \"netem apply error: %v\", err)\n   }\n   return &empty.Empty{}, nil\n}\n\n// Apply applies a netem on eth0 in pid related namespace\n\nfunc Apply(netem *pb.Netem, pid uint32) error {\n   log.Info(\"Apply netem on PID\", \"pid\", pid)\n   ns, err := netns.GetFromPath(GenNetnsPath(pid))\n   if err != nil {\n       log.Error(err, \"failed to find network namespace\", \"pid\", pid)\n       return errors.Trace(err)\n   }\n   defer ns.Close()\n   handle, err := netlink.NewHandleAt(ns)\n   if err != nil {\n       log.Error(err, \"failed to get handle at network namespace\", \"network namespace\", ns)\n       return err\n   }\n   link, err := handle.LinkByName(\"eth0\") // TODO: check whether interface name is eth0\n   if err != nil {\n       log.Error(err, \"failed to find eth0 interface\")\n       return errors.Trace(err)\n   }\n   netemQdisc := netlink.NewNetem(netlink.QdiscAttrs{\n       LinkIndex: link.Attrs().Index,\n       Handle:    netlink.MakeHandle(1, 0),\n       Parent:    netlink.HANDLE_ROOT,\n   }, ToNetlinkNetemAttrs(netem))\n   if err = handle.QdiscAdd(netemQdisc); err != nil {\n       if !strings.Contains(err.Error(), \"file exists\") {\n           log.Error(err, \"failed to add Qdisc\")\n           return errors.Trace(err)\n       }\n   }\n   return nil\n}\n```",
      "source_content_hash": "05088062971933220f61b10bfda2915dd8472a83fd6ca5e51adde48373a179c1",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_d5f63a23"
      }
    },
    {
      "segment_id": "1f92e934",
      "source_content": "Finally, the [`vishvananda/netlink` library](https://github.com/vishvananda/netlink) operates the Linux network interface to complete the job.",
      "source_content_hash": "5a0ee6e9a0de898aea43ad5ed5f81e0ad1ee375c0ba729d90cbd0a518fffd745",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "最終的に、[`vishvananda/netlink`ライブラリ](https://github.com/vishvananda/netlink)がLinuxネットワークインターフェースを操作して処理を完了させます。"
      }
    },
    {
      "segment_id": "45d5dee4",
      "source_content": "From here, `NetworkChaos` manipulates the Linux host network to create chaos. It includes tools such as iptables and ipset.",
      "source_content_hash": "ac80604f4ea73d3b6aa96db3b5e5ec437d32478d953f78d0b04e84b0a6101af4",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "ここから、`NetworkChaos`はLinuxホストネットワークを操作してカオスを発生させます。iptablesやipsetなどのツールが含まれます。"
      }
    },
    {
      "segment_id": "83d7d3bc",
      "source_content": "In Chaos Daemon's Dockerfile, you can see the Linux tool chain that it depends on:",
      "source_content_hash": "2dcf8ae565abd1f8c3f6b8279e2396b850e10d57384f8dc7ee39295bbc589640",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Chaos DaemonのDockerfileでは、依存しているLinuxツールチェーンを確認できます："
      }
    },
    {
      "segment_id": "f24a5721",
      "source_content": "```dockerfile\nRUN apt-get update && \\\n   apt-get install -y tzdata iptables ipset stress-ng iproute2 fuse util-linux procps curl && \\\n   rm -rf /var/lib/apt/lists/*\n```",
      "source_content_hash": "2f72f092a9eceef73995b1cc31ba6cdbb2942f6c1c4ca292a9cbe37b39eeb32a",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_f24a5721"
      }
    },
    {
      "segment_id": "73b08a54",
      "source_content": "### Stress test",
      "source_content_hash": "c97ea04b1c44bf04ccefe2df7a16280ef1c77c2540088c3737afcb5638e9b408",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "### ストレステスト"
      }
    },
    {
      "segment_id": "7e031d10",
      "source_content": "Chaos Daemon also implements `StressChaos`. After the Controller Manager calculates the rules, it sends the task to the specific `Daemon`. The assembled parameters are shown below. They are combined into command execution parameters and appended to the `stress-ng` command for execution.",
      "source_content_hash": "2587f026bbe801fcb66db05d1f2910a76e6fab02ccbcfcd5314838a16372c5ff",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Chaos Daemonは`StressChaos`も実装しています。Controller Managerがルールを計算した後、タスクを特定の`Daemon`に送信します。組み立てられたパラメータを以下に示します。これらはコマンド実行パラメータに結合され、`stress-ng`コマンドに追加されて実行されます。"
      }
    },
    {
      "segment_id": "31df1954",
      "source_content": "```go\n// Normalize the stressors to comply with stress-ng\nfunc (in *Stressors) Normalize() (string, error) {\n   stressors := \"\"\n   if in.MemoryStressor != nil && in.MemoryStressor.Workers != 0 {\n       stressors += fmt.Sprintf(\" --vm %d --vm-keep\", in.MemoryStressor.Workers)\n       if len(in.MemoryStressor.Size) != 0 {\n           if in.MemoryStressor.Size[len(in.MemoryStressor.Size)-1] != '%' {\n               size, err := units.FromHumanSize(string(in.MemoryStressor.Size))\n               if err != nil {\n                   return \"\", err\n               }\n               stressors += fmt.Sprintf(\" --vm-bytes %d\", size)\n           } else {\n               stressors += fmt.Sprintf(\" --vm-bytes %s\",\n                   in.MemoryStressor.Size)\n           }\n       }\n       if in.MemoryStressor.Options != nil {\n           for _, v := range in.MemoryStressor.Options {\n               stressors += fmt.Sprintf(\" %v \", v)\n           }\n       }\n   }\n   if in.CPUStressor != nil && in.CPUStressor.Workers != 0 {\n       stressors += fmt.Sprintf(\" --cpu %d\", in.CPUStressor.Workers)\n       if in.CPUStressor.Load != nil {\n           stressors += fmt.Sprintf(\" --cpu-load %d\",\n               *in.CPUStressor.Load)\n       }\n       if in.CPUStressor.Options != nil {\n           for _, v := range in.CPUStressor.Options {\n               stressors += fmt.Sprintf(\" %v \", v)\n           }\n       }\n   }\n   return stressors, nil\n}\n```",
      "source_content_hash": "7608ec13e201fbdde6c97199220933471c731b7ae0c1e33dec42a55660aa64a7",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_31df1954"
      }
    },
    {
      "segment_id": "d04a3ef5",
      "source_content": "The Chaos Daemon server side processes the function's execution command to call the official Go package `os/exec`. For details, see the [`pkg/chaosdaemon/stress_server_linux.go`](https://github.com/chaos-mesh/chaos-mesh/blob/98af3a0e7832a4971d6b133a32069539d982ef0a/pkg/chaosdaemon/stress_server_linux.go#L33) file. There is also a file with the same name that ends with darwin. `*_darwin` files prevent possible errors when the program is running on macOS.",
      "source_content_hash": "3ae42812b3895c91bef30d3497d5aa2d66b6c907727f9e9dbac122370a435308",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Chaos Daemonサーバー側では、関数の実行コマンドを処理するために公式Goパッケージ`os/exec`を呼び出します。詳細は[`pkg/chaosdaemon/stress_server_linux.go`](https://github.com/chaos-mesh/chaos-mesh/blob/98af3a0e7832a4971d6b133a32069539d982ef0a/pkg/chaosdaemon/stress_server_linux.go#L33)ファイルを参照してください。darwinで終わる同名のファイルもあります。`*_darwin`ファイルは、プログラムがmacOSで実行される際の潜在的なエラーを防ぎます。"
      }
    },
    {
      "segment_id": "dd78ef80",
      "source_content": "The code uses the [`shirou/gopsutil`](https://github.com/shirou/gopsutil) package to obtain the PID process status and reads the stdout and stderr standard outputs. I've seen this processing mode in [`hashicorp/go-plugin`](https://github.com/hashicorp/go-plugin), and go-plugin does this better.",
      "source_content_hash": "f64e6c15a9acae9d8bb47e002301ad745084127ba537ceb4d936db130177f721",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "このコードは[`shirou/gopsutil`](https://github.com/shirou/gopsutil)パッケージを使用してPIDプロセスステータスを取得し、stdoutとstderrの標準出力を読み取ります。この処理モードは[`hashicorp/go-plugin`](https://github.com/hashicorp/go-plugin)でも見られ、go-pluginの方が優れています。"
      }
    },
    {
      "segment_id": "3f6b512a",
      "source_content": "### I/O fault injection",
      "source_content_hash": "f288433aab1965cdc918ab6406afd8ed818d32f454091fb978331d096be02dec",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "### I/O障害の注入"
      }
    },
    {
      "segment_id": "e91bdcd9",
      "source_content": "[Pull request #826](https://github.com/chaos-mesh/chaos-mesh/pull/826) introduces a new implementation of IOChaos, without the use of sidecar injection. It uses Chaos Daemon to directly manipulate the Linux namespace through the underlying commands of the [runc](https://github.com/opencontainers/runc) container and runs the [chaos-mesh/toda](https://github.com/chaos-mesh/toda) FUSE program developed by Rust to inject container I/O chaos. The [JSON-RPC 2.0](https://pkg.go.dev/github.com/ethereum/go-ethereum/rpc) protocol is used to communicate between toda and the control plane.",
      "source_content_hash": "c30c44356af74ec79783c137f5d629fe689bfd6bc3896a740fa90c292b68d2b1",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "[プルリクエスト #826](https://github.com/chaos-mesh/chaos-mesh/pull/826)では、サイドカー注入を使用しない新しいIOChaosの実装が導入されています。Chaos Daemonを使用して、[runc](https://github.com/opencontainers/runc)コンテナの低レベルコマンドを通じてLinuxネームスペースを直接操作し、Rustで開発された[chaos-mesh/toda](https://github.com/chaos-mesh/toda) FUSEプログラムを実行してコンテナI/Oカオスを注入します。[JSON-RPC 2.0](https://pkg.go.dev/github.com/ethereum/go-ethereum/rpc)プロトコルがtodaとコントロールプレーン間の通信に使用されます。"
      }
    },
    {
      "segment_id": "4bfb1f31",
      "source_content": "The new IOChaos implementation doesn't modify the Pod resources. When you define the IOChaos chaos experiment, for each Pod filtered by the selector field, a corresponding PodIOChaos resource is created. PodIoChaos' [owner reference](https://kubernetes.io/docs/concepts/overview/working-with-objects/owners-dependents/) is the Pod. At the same time, a set of [finalizers](https://kubernetes.io/docs/concepts/overview/working-with-objects/finalizers/) is added to PodIoChaos to release PodIoChaos resources before PodIoChaos is deleted.",
      "source_content_hash": "d68d2b6de983ce2ac0f8bd4d834eccbb966eab29a3a4add58b1ed7fc3b09415f",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "新しいIOChaosの実装では、Podリソースを変更しません。IOChaosのカオス実験を定義する際、selectorフィールドでフィルタリングされた各Podに対して、対応するPodIOChaosリソースが作成されます。PodIOChaosの[オーナーリファレンス](https://kubernetes.io/docs/concepts/overview/working-with-objects/owners-dependents/)はPodになります。同時に、PodIOChaosが削除される前にリソースを解放するため、[ファイナライザー](https://kubernetes.io/docs/concepts/overview/working-with-objects/finalizers/)のセットがPodIOChaosに追加されます。"
      }
    },
    {
      "segment_id": "253b84c5",
      "source_content": "```go\n// Apply implements the reconciler.InnerReconciler.Apply\n\nfunc (r *Reconciler) Apply(ctx context.Context, req ctrl.Request, chaos v1alpha1.InnerObject) error {\n   iochaos, ok := chaos.(*v1alpha1.IoChaos)\n   if !ok {\n       err := errors.New(\"chaos is not IoChaos\")\n       r.Log.Error(err, \"chaos is not IoChaos\", \"chaos\", chaos)\n       return err\n   }\n   source := iochaos.Namespace + \"/\" + iochaos.Name\n   m := podiochaosmanager.New(source, r.Log, r.Client)\n   pods, err := utils.SelectAndFilterPods(ctx, r.Client, r.Reader, &iochaos.Spec)\n   if err != nil {\n       r.Log.Error(err, \"failed to select and filter pods\")\n       return err\n   }\n   r.Log.Info(\"applying iochaos\", \"iochaos\", iochaos)\n   for _, pod := range pods {\n       t := m.WithInit(types.NamespacedName{\n           Name:      pod.Name,\n           Namespace: pod.Namespace,\n       })\n\n       // TODO: support chaos on multiple volume\n\n       t.SetVolumePath(iochaos.Spec.VolumePath)\n       t.Append(v1alpha1.IoChaosAction{\n           Type: iochaos.Spec.Action,\n           Filter: v1alpha1.Filter{\n               Path:    iochaos.Spec.Path,\n               Percent: iochaos.Spec.Percent,\n               Methods: iochaos.Spec.Methods,\n           },\n           Faults: []v1alpha1.IoFault{\n               {\n                   Errno:  iochaos.Spec.Errno,\n                   Weight: 1,\n               },\n           },\n           Latency:          iochaos.Spec.Delay,\n           AttrOverrideSpec: iochaos.Spec.Attr,\n           Source:           m.Source,\n       })\n       key, err := cache.MetaNamespaceKeyFunc(&pod)\n       if err != nil {\n           return err\n       }\n       iochaos.Finalizers = utils.InsertFinalizer(iochaos.Finalizers, key)\n   }\n   r.Log.Info(\"commiting updates of podiochaos\")\n   err = m.Commit(ctx)\n   if err != nil {\n       r.Log.Error(err, \"fail to commit\")\n       return err\n   }\n   r.Event(iochaos, v1.EventTypeNormal, utils.EventChaosInjected, \"\")\n   return nil\n}\n```",
      "source_content_hash": "983e23c2c907d5f8f92f9e2d8a7c875c58b16b29350791e0c5473405a025ef7f",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_253b84c5"
      }
    },
    {
      "segment_id": "a5a5c34e",
      "source_content": "In the controller of the PodIoChaos resource, Controller Manager encapsulates the resource into parameters and calls the Chaos Daemon interface to process the parameters.",
      "source_content_hash": "19effb6ae14afd7e98149eb65cf40cf125a988ff915c12005c91d853d471d6f5",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "PodIOChaosリソースのコントローラーでは、Controller Managerがリソースをパラメータにカプセル化し、Chaos Daemonインターフェースを呼び出して処理します。"
      }
    },
    {
      "segment_id": "5ceeeefa",
      "source_content": "```go\n// Apply flushes io configuration on pod\n\nfunc (h *Handler) Apply(ctx context.Context, chaos *v1alpha1.PodIoChaos) error {\n   h.Log.Info(\"updating io chaos\", \"pod\", chaos.Namespace+\"/\"+chaos.Name, \"spec\", chaos.Spec)\n   ...\n   res, err := pbClient.ApplyIoChaos(ctx, &pb.ApplyIoChaosRequest{\n       Actions:     input,\n       Volume:      chaos.Spec.VolumeMountPath,\n       ContainerId: containerID,\n       Instance:  chaos.Spec.Pid,\n       StartTime: chaos.Spec.StartTime,\n   })\n   if err != nil {\n       return err\n   }\n   chaos.Spec.Pid = res.Instance\n   chaos.Spec.StartTime = res.StartTime\n   chaos.OwnerReferences = []metav1.OwnerReference{\n       {\n           APIVersion: pod.APIVersion,\n           Kind:       pod.Kind,\n           Name:       pod.Name,\n           UID:        pod.UID,\n       },\n   }\n   return nil\n}\n```",
      "source_content_hash": "38708a1a5eed1297817356f45c3920600832241724b2f1722bfb14739ffe0cb1",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_5ceeeefa"
      }
    },
    {
      "segment_id": "c829cc4b",
      "source_content": "The `pkg/chaosdaemon/iochaos_server.go` file processes IOChaos. ​​In this file, a FUSE program needs to be injected into the container. As discussed in issue [#2305](https://github.com/chaos-mesh/chaos-mesh/issues/2305) on GitHub, the `/usr/local/bin/nsexec -l- p /proc/119186/ns/pid -m /proc/119186/ns/mnt - /usr/local/bin/toda --path /tmp --verbose info` command is executed to run the toda program under the same namespace as the Pod.",
      "source_content_hash": "1593389e2b647cff8446fe15740d5cf193227b7c52df682e4de6a6537ea72b30",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "`pkg/chaosdaemon/iochaos_server.go`ファイルではIOChaosを処理します。このファイルでは、コンテナにFUSEプログラムを注入する必要があります。GitHubのissue [#2305](https://github.com/chaos-mesh/chaos-mesh/issues/2305)で議論されているように、`/usr/local/bin/nsexec -l- p /proc/119186/ns/pid -m /proc/119186/ns/mnt - /usr/local/bin/toda --path /tmp --verbose info`コマンドを実行し、Podと同じnamespaceでtodaプログラムを実行します。"
      }
    },
    {
      "segment_id": "d27cbc80",
      "source_content": "```go\nfunc (s *DaemonServer) ApplyIOChaos(ctx context.Context, in *pb.ApplyIOChaosRequest) (*pb.ApplyIOChaosResponse, error) {\n   ...\n   pid, err := s.crClient.GetPidFromContainerID(ctx, in.ContainerId)\n   if err != nil {\n       log.Error(err, \"error while getting PID\")\n       return nil, err\n   }\n   args := fmt.Sprintf(\"--path %s --verbose info\", in.Volume)\n   log.Info(\"executing\", \"cmd\", todaBin+\" \"+args)\n   processBuilder := bpm.DefaultProcessBuilder(todaBin, strings.Split(args, \" \")...).\n       EnableLocalMnt().\n       SetIdentifier(in.ContainerId)\n   if in.EnterNS {\n       processBuilder = processBuilder.SetNS(pid, bpm.MountNS).SetNS(pid, bpm.PidNS)\n   }\n   ...\n\n   // Calls JSON RPC\n\n   client, err := jrpc.DialIO(ctx, receiver, caller)\n   if err != nil {\n       return nil, err\n   }\n   cmd := processBuilder.Build()\n   procState, err := s.backgroundProcessManager.StartProcess(cmd)\n   if err != nil {\n       return nil, err\n   }\n   ...\n}\n```",
      "source_content_hash": "a53cbcb58bcc3406d01fab68b0e7e39c63499364921a246627f732b89e77a45a",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_d27cbc80"
      }
    },
    {
      "segment_id": "7f0cded5",
      "source_content": "The following code sample builds the running commands. These commands are the underlying namespace isolation implementation of runc:",
      "source_content_hash": "7991881ed8da30fefd0880270e50c53d209d12109feb4c159efc69a025501e27",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "以下のコードサンプルは、実行コマンドを構築します。これらのコマンドは、runcの基盤となるnamespace隔離の実装です："
      }
    },
    {
      "segment_id": "647125dc",
      "source_content": "```go\n// GetNsPath returns corresponding namespace path\n\nfunc GetNsPath(pid uint32, typ NsType) string {\n   return fmt.Sprintf(\"%s/%d/ns/%s\", DefaultProcPrefix, pid, string(typ))\n}\n\n// SetNS sets the namespace of the process\n\nfunc (b *ProcessBuilder) SetNS(pid uint32, typ NsType) *ProcessBuilder {\n   return b.SetNSOpt([]nsOption{{\n       Typ:  typ,\n       Path: GetNsPath(pid, typ),\n   }})\n}\n\n// Build builds the process\n\nfunc (b *ProcessBuilder) Build() *ManagedProcess {\n   args := b.args\n   cmd := b.cmd\n   if len(b.nsOptions) > 0 {\n       args = append([]string{\"--\", cmd}, args...)\n       for _, option := range b.nsOptions {\n           args = append([]string{\"-\" + nsArgMap[option.Typ], option.Path}, args...)\n       }\n       if b.localMnt {\n           args = append([]string{\"-l\"}, args...)\n       }\n       cmd = nsexecPath\n   }\n   ...\n}\n```",
      "source_content_hash": "98c9ea8059d0409b23db959c59124c83bf6f2377df7fd01099338d4fae4e533e",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_647125dc"
      }
    },
    {
      "segment_id": "11e4b3f0",
      "source_content": "## Control plane",
      "source_content_hash": "d7c08e14c7d7de3b939b0849903b8128fbac570bd1c9026e09acf08595237d7d",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "## コントロールプレーン"
      }
    },
    {
      "segment_id": "6ba1041f",
      "source_content": "Chaos Mesh is an open-source chaos engineering system under the Apache 2.0 protocol. As discussed above, it has rich capabilities and a good ecosystem. The maintenance team developed the [`chaos-mesh/toda`](https://github.com/chaos-mesh/toda) FUSE based on the chaos system, the [`chaos-mesh/k8s_dns_chaos`](https://github.com/chaos-mesh/k8s_dns_chaos) CoreDNS chaos plug-in, and Berkeley Packet Filter (BPF)-based kernel error injection [`chaos-mesh/bpfki`](https://github.com/chaos-mesh/bpfki).",
      "source_content_hash": "29de334b2f31a201730766f5fa654319a30f58b0895d3590700f27c14b09f670",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Chaos MeshはApache 2.0ライセンスのオープンソースカオスエンジニアリングシステムです。前述のように、豊富な機能と良好なエコシステムを備えています。メンテナンスチームは、カオスシステムに基づいて[`chaos-mesh/toda`](https://github.com/chaos-mesh/toda) FUSE、[`chaos-mesh/k8s_dns_chaos`](https://github.com/chaos-mesh/k8s_dns_chaos) CoreDNSカオスプラグイン、およびBerkeley Packet Filter (BPF)ベースのカーネルエラーインジェクション[`chaos-mesh/bpfki`](https://github.com/chaos-mesh/bpfki)を開発しました。"
      }
    },
    {
      "segment_id": "8f554a02",
      "source_content": "Now, I'll describe the server side code required to build an end-user-oriented chaos engineering platform. This implementation is only an example—not necessarily the best example. If you want to see the development practice on a real world platform, you can refer to Chaos Mesh's [Dashboard](https://github.com/chaos-mesh/chaos-mesh/tree/master/pkg/dashboard). It uses the [`uber-go/fx`](https://github.com/uber-go/fx) dependency injection framework and the controller runtime's manager mode.",
      "source_content_hash": "845c33b920268c8f854c28c71e3358506337be56f380b540746af954f8a244c2",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "ここでは、エンドユーザー向けのカオスエンジニアリングプラットフォームを構築するために必要なサーバーサイドコードについて説明します。この実装はあくまで例であり、必ずしも最良の例ではありません。実際のプラットフォームでの開発実践を見たい場合は、Chaos Meshの[Dashboard](https://github.com/chaos-mesh/chaos-mesh/tree/master/pkg/dashboard)を参照してください。これは[`uber-go/fx`](https://github.com/uber-go/fx)依存性注入フレームワークと、コントローラーランタイムのマネージャーモードを使用しています。"
      }
    },
    {
      "segment_id": "477f2f8b",
      "source_content": "### Key Chaos Mesh features",
      "source_content_hash": "06e65a3a8c1a46d6990bd70199738a9b12f159c5dd067ca6fd569438ccea3a20",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "### Chaos Meshの主要機能"
      }
    },
    {
      "segment_id": "e6bf9a6c",
      "source_content": "As shown in the Chaos Mesh workflow below, we need to implement a server that sends YAML to the Kubernetes API. Chaos Controller Manager implements complex rule verification and rule delivery to Chaos Daemon. If you want to use Chaos Mesh with your own platform, you only need to connect to the process of creating CRD resources.",
      "source_content_hash": "4dd90ae18d02081b557eb3c6b3cde0f392bc3a45b1e5e0c948743c2de2d90afd",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "以下のChaos Meshのワークフローに示すように、YAMLをKubernetes APIに送信するサーバーを実装する必要があります。Chaos Controller Managerは、複雑なルール検証とChaos Daemonへのルール配信を実装します。独自のプラットフォームでChaos Meshを使用する場合は、CRDリソースを作成するプロセスに接続するだけで済みます。"
      }
    },
    {
      "segment_id": "17b95bd5",
      "source_content": "![Chaos Mesh's basic workflow](/img/blog/chaos-mesh-basic-workflow.png)",
      "source_content_hash": "6b8c5b9e445b273fe43f8bcbc1c3598d8726e9c74b686afc990d4f99eba5c829",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "![Chaos Meshの基本的なワークフロー](/img/blog/chaos-mesh-basic-workflow.png)"
      }
    },
    {
      "segment_id": "5fe249dd",
      "source_content": "Let's take a look at the example on the Chaos Mesh website:",
      "source_content_hash": "be736d6263951aeb5d4b4e8e2885b05e2175357faf107edf87b73eb2e0d74efc",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Chaos Meshウェブサイトの例を見てみましょう："
      }
    },
    {
      "segment_id": "79094e7f",
      "source_content": "```go\nimport (\n   \"context\"\n   \"github.com/pingcap/chaos-mesh/api/v1alpha1\"\n   \"sigs.k8s.io/controller-runtime/pkg/client\"\n)\n\nfunc main() {\n   ...\n   delay := &chaosv1alpha1.NetworkChaos{\n       Spec: chaosv1alpha1.NetworkChaosSpec{...},\n   }\n   k8sClient := client.New(conf, client.Options{ Scheme: scheme.Scheme })\n   k8sClient.Create(context.TODO(), delay)\n   k8sClient.Delete(context.TODO(), delay)\n}\n```",
      "source_content_hash": "4c22a4025e58e734cdc5c765dd7adaf46deea1b6dd89df1c9ba0b20c7214fdc9",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_79094e7f"
      }
    },
    {
      "segment_id": "9d789e30",
      "source_content": "Chaos Mesh provides APIs corresponding to all CRDs. We use the [controller-runtime](https://github.com/kubernetes-sigs/controller-runtime) developed by Kubernetes [API Machinery SIG](https://github.com/kubernetes/community/tree/master/sig-api-machinery) to simplify the interaction with the Kubernetes API.",
      "source_content_hash": "b7967a52c78534f411c789e98f98c28886334a4886751429ed7c8e8b2155f8a5",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Chaos Meshは、すべてのCRDに対応するAPIを提供します。Kubernetes [API Machinery SIG](https://github.com/kubernetes/community/tree/master/sig-api-machinery)が開発した[controller-runtime](https://github.com/kubernetes-sigs/controller-runtime)を使用して、Kubernetes APIとのやり取りを簡素化します。"
      }
    },
    {
      "segment_id": "b8d76c94",
      "source_content": "### Inject chaos",
      "source_content_hash": "b3b6ae663f0be18b4feaacfed3a36322b593a1a9f94a59645a24bab0e7355b72",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "### カオスの注入"
      }
    },
    {
      "segment_id": "cff30da4",
      "source_content": "Suppose we want to create a `PodKill` resource by calling a program. After the resource is sent to the Kubernetes API server, it passes Chaos Controller Manager's [validating admission controller](https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/) to verify data. When we create a chaos experiment, if the admission controller fails to verify the input data, it returns an error to the client. For specific parameters, you can read [Create experiments using YAML configuration files](https://chaos-mesh.org/docs/simulate-pod-chaos-on-kubernetes/#create-experiments-using-yaml-configuration-files).",
      "source_content_hash": "0a27b29b112550a68a38ec238bce68d0821b7d09c127b324de7f2043a89b70a1",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "プログラムを呼び出して`PodKill`リソースを作成したい場合を考えます。リソースがKubernetes APIサーバーに送信されると、Chaos Controller Managerの[validating admission controller](https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/)を通過してデータが検証されます。カオス実験を作成する際、admission controllerが入力データの検証に失敗すると、クライアントにエラーが返されます。具体的なパラメータについては、[YAML設定ファイルを使用した実験の作成](https://chaos-mesh.org/docs/simulate-pod-chaos-on-kubernetes/#create-experiments-using-yaml-configuration-files)を参照してください。"
      }
    },
    {
      "segment_id": "36a7c2db",
      "source_content": "`NewClient` creates a Kubernetes API client. You can refer to this example:",
      "source_content_hash": "3f677eb3d9a07eaff45ac414d3bd7cea1a265a3ddc17c2af6a06e2f23b9a3e64",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "`NewClient`はKubernetes APIクライアントを作成します。この例を参照できます："
      }
    },
    {
      "segment_id": "26463657",
      "source_content": "```go\npackage main\n\nimport (\n   \"context\"\n   \"controlpanel\"\n   \"log\"\n   \"github.com/chaos-mesh/chaos-mesh/api/v1alpha1\"\n   \"github.com/pkg/errors\"\n   metav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n)\n\nfunc applyPodKill(name, namespace string, labels map[string]string) error {\n   cli, err := controlpanel.NewClient()\n   if err != nil {\n       return errors.Wrap(err, \"create client\")\n   }\n   cr := &v1alpha1.PodChaos{\n       ObjectMeta: metav1.ObjectMeta{\n           GenerateName: name,\n           Namespace:    namespace,\n       },\n       Spec: v1alpha1.PodChaosSpec{\n           Action: v1alpha1.PodKillAction,\n           ContainerSelector: v1alpha1.ContainerSelector{\n               PodSelector: v1alpha1.PodSelector{\n                   Mode: v1alpha1.OnePodMode,\n                   Selector: v1alpha1.PodSelectorSpec{\n                       Namespaces:     []string{namespace},\n                       LabelSelectors: labels,\n                   },\n               },\n           },\n       },\n   }\n\n   if err := cli.Create(context.Background(), cr); err != nil {\n       return errors.Wrap(err, \"create podkill\")\n   }\n   return nil\n}\n```",
      "source_content_hash": "e6f54cc5b92b88d411beaca338354982c99a1cac05db7b30728b0a67dc31f605",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_26463657"
      }
    },
    {
      "segment_id": "929f4d2d",
      "source_content": "The log output of the running program is:",
      "source_content_hash": "3b38f55722c5a565d101828f472e3edbce12f8a421220ba009b49e7b9bdd2495",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "実行プログラムのログ出力は以下の通りです："
      }
    },
    {
      "segment_id": "c4c948f3",
      "source_content": "```bash\nI1021 00:51:55.225502   23781 request.go:665] Waited for 1.033116256s due to client-side throttling, not priority and fairness, request: GET:https://***\n2021/10/21 00:51:56 apply podkill\n```",
      "source_content_hash": "d3e54cbd3baebed54d1d7f6fe22db926663d0e73fc32af80de69d0391bf9c11b",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_c4c948f3"
      }
    },
    {
      "segment_id": "92bceadb",
      "source_content": "Use kubectl to check the status of the `PodKill` resource:",
      "source_content_hash": "9474603d084a51d7df319ff803705b89426c3930a07e24517fa43f3ef9d80d43",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "kubectlを使用して`PodKill`リソースのステータスを確認します："
      }
    },
    {
      "segment_id": "f291b8f1",
      "source_content": "```bash\n$ k describe podchaos.chaos-mesh.org -n dev podkillvjn77\nName:         podkillvjn77\nNamespace:    dev\nLabels:       <none>\nAnnotations:  <none>\nAPI Version:  chaos-mesh.org/v1alpha1\nKind:         PodChaos\n\nMetadata:\n Creation Timestamp:  2021-10-20T16:51:56Z\n Finalizers:\n   chaos-mesh/records\n Generate Name:     podkill\n Generation:        7\n Resource Version:  938921488\n Self Link:         /apis/chaos-mesh.org/v1alpha1/namespaces/dev/podchaos/podkillvjn77\n UID:               afbb40b3-ade8-48ba-89db-04918d89fd0b\n\nSpec:\n Action:        pod-kill\n Grace Period:  0\n Mode:          one\n Selector:\n   Label Selectors:\n     app:  nginx\n   Namespaces:\n     dev\n\nStatus:\n Conditions:\n   Reason:\n   Status:  False\n   Type:    Paused\n   Reason:\n   Status:  True\n   Type:    Selected\n   Reason:\n   Status:  True\n   Type:    AllInjected\n   Reason:\n   Status:  False\n   Type:    AllRecovered\n\n Experiment:\n   Container Records:\n     Id:            dev/nginx\n     Phase:         Injected\n     Selector Key:  .\n   Desired Phase:   Run\n\nEvents:\n Type    Reason           Age    From          Message\n ----    ------           ----   ----          -------\n Normal  FinalizerInited  6m35s  finalizer     Finalizer has been inited\n Normal  Updated          6m35s  finalizer     Successfully update finalizer of resource\n Normal  Updated          6m35s  records       Successfully update records of resource\n Normal  Updated          6m35s  desiredphase  Successfully update desiredPhase of resource\n Normal  Applied          6m35s  records       Successfully apply chaos for dev/nginx\n Normal  Updated          6m35s  records       Successfully update records of resource\n```",
      "source_content_hash": "02b4c2d2e0c18e4183e5dd6e4d696f59e2a831e9d67016538f0dc5d3f519c172",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_f291b8f1"
      }
    },
    {
      "segment_id": "ec74b948",
      "source_content": "The control plane also needs to query and acquire Chaos resources, so that platform users can view all chaos experiments' implementation status and manage them. To achieve this, we can call the `REST` API to send the `Get` or `List` request. But in practice, we need to pay attention to the details. At our company, we've noticed that each time the controller requests the full amount of resource data, the load of the Kubernetes API server increases.",
      "source_content_hash": "5a85d4b6196392cb2dcc71e6946a3737290b5e6eb79a84d9ad51aba43c932b66",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "コントロールプレーンはまた、Chaosリソースをクエリおよび取得する必要があります。これにより、プラットフォームユーザーはすべてのカオス実験の実施状況を確認し、管理できます。これを実現するために、`REST` APIを呼び出して`Get`または`List`リクエストを送信できます。しかし実際には、細部に注意が必要です。当社では、コントローラーが毎回リソースデータの全量をリクエストするたびに、Kubernetes APIサーバーの負荷が増加することが観察されています。"
      }
    },
    {
      "segment_id": "413a2594",
      "source_content": "I recommend that you read the [How to use the controller-runtime client](https://zoetrope.github.io/kubebuilder-training/controller-runtime/client.html) (in Japanese) controller runtime tutorial. If you don't understand Japanese, you can still learn a lot from the tutorial by reading the source code. It covers many details. For example, by default, the controller runtime reads kubeconfig, flags, environment variables, and the service account automatically mounted in the Pod from multiple locations. [Pull request #21](https://github.com/armosec/kubescape/pull/21) for [`armosec/kubescape`](https://github.com/armosec/kubescape) uses this feature. This tutorial also includes common operations, such as how to paginate, update, and overwrite objects. I haven't seen any English tutorials that are so detailed.",
      "source_content_hash": "c3c035c1790256831f15d5dc20265ef756c4fe2a2b42fb81174a6a4dc73d35f6",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "[controller-runtimeクライアントの使用方法](https://zoetrope.github.io/kubebuilder-training/controller-runtime/client.html)（日本語）のチュートリアルを読むことをお勧めします。日本語が理解できなくても、ソースコードを読むことで多くのことを学べます。このチュートリアルには多くの詳細が含まれています。例えば、デフォルトではcontroller-runtimeはkubeconfig、フラグ、環境変数、およびPodに自動的にマウントされたサービスアカウントを複数の場所から読み取ります。[`armosec/kubescape`](https://github.com/armosec/kubescape)の[Pull request #21](https://github.com/armosec/kubescape/pull/21)はこの機能を使用しています。このチュートリアルには、ページネーション、オブジェクトの更新や上書きなど、一般的な操作も含まれています。これほど詳細な英語のチュートリアルは見たことがありません。"
      }
    },
    {
      "segment_id": "3026c350",
      "source_content": "Here are examples of `Get` and `List` requests:",
      "source_content_hash": "ce3e3f5c7eba014ea99c6e7db80ffbe7e4c26f5882e51cbe7fc579a5ac56a9fa",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "以下は`Get`および`List`リクエストの例です："
      }
    },
    {
      "segment_id": "02cf064a",
      "source_content": "```go\npackage controlpanel\n\nimport (\n   \"context\"\n   \"github.com/chaos-mesh/chaos-mesh/api/v1alpha1\"\n   \"github.com/pkg/errors\"\n   \"sigs.k8s.io/controller-runtime/pkg/client\"\n)\n\nfunc GetPodChaos(name, namespace string) (*v1alpha1.PodChaos, error) {\n   cli := mgr.GetClient()\n   item := new(v1alpha1.PodChaos)\n   if err := cli.Get(context.Background(), client.ObjectKey{Name: name, Namespace: namespace}, item); err != nil {\n       return nil, errors.Wrap(err, \"get cr\")\n   }\n   return item, nil\n}\n\nfunc ListPodChaos(namespace string, labels map[string]string) ([]v1alpha1.PodChaos, error) {\n   cli := mgr.GetClient()\n   list := new(v1alpha1.PodChaosList)\n   if err := cli.List(context.Background(), list, client.InNamespace(namespace), client.MatchingLabels(labels)); err != nil {\n       return nil, err\n   }\n   return list.Items, nil\n}\n```",
      "source_content_hash": "8b313300d3168432b966511cbca276e65db21406e6014e1c12dc8a09fccb4239",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_02cf064a"
      }
    },
    {
      "segment_id": "c3d63f8a",
      "source_content": "This example uses the manager. This mode prevents the cache mechanism from repetitively fetching large amounts of data. The following [figure](https://zoetrope.github.io/kubebuilder-training/controller-runtime/client.html) shows the workflow:",
      "source_content_hash": "e5f50c5a30b19e7d8c094f2e2e46add0b2e07a5d0a3a37701a15506b9fab1fd9",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "この例ではマネージャーを使用しています。このモードでは、キャッシュメカニズムが大量のデータを繰り返し取得するのを防ぎます。以下の[図](https://zoetrope.github.io/kubebuilder-training/controller-runtime/client.html)にワークフローを示します："
      }
    },
    {
      "segment_id": "af5fa1f1",
      "source_content": "1. Get the Pod.\n\n2. Get the `List` request's full data for the first time.\n\n3. Update the cache when the watch data changes.",
      "source_content_hash": "dff5a8a3c549f761aa5b464827a9b966a8a34fc6849f7f3a491fdc4c4dfd5f21",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "1. Podを取得する。\n\n2. `List`リクエストの全データを初めて取得する。\n\n3. watchデータが変更されたときにキャッシュを更新する。"
      }
    },
    {
      "segment_id": "d1d04358",
      "source_content": "![List request](/img/blog/list-request.png)",
      "source_content_hash": "fcdc40e442673d97f4a44c3b519282a7e387b46dad41e6d0100564f04d329b11",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "![Listリクエスト](/img/blog/list-request.png)"
      }
    },
    {
      "segment_id": "18c0bc86",
      "source_content": "### Orchestrate chaos",
      "source_content_hash": "18c38c9bf6f95e7557669602d0749b7cc0cb330e2523a515d6e2dd97d017db6e",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "### カオスのオーケストレーション"
      }
    },
    {
      "segment_id": "16ad9b8d",
      "source_content": "The container runtime interface (CRI) container runtime provides strong underlying isolation capabilities that can support the stable operation of the container. But for more complex and scalable scenarios, container orchestration is required. Chaos Mesh also provides [`Schedule`](https://chaos-mesh.org/docs/define-scheduling-rules/) and [`Workflow`](https://chaos-mesh.org/docs/create-chaos-mesh-workflow/) features. Based on the set `Cron` time, `Schedule` can trigger faults regularly and at intervals. `Workflow` can schedule multiple fault tests like Argo Workflows.",
      "source_content_hash": "f63d14605575704a07737da71274aa17eb6099ca15ee103830c6971066e7eb86",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "CRI（Container Runtime Interface）ランタイムは、コンテナの安定した動作をサポートする強力な基盤分離機能を提供します。しかし、より複雑でスケーラブルなシナリオでは、コンテナオーケストレーションが必要です。Chaos Meshはまた、[`Schedule`](https://chaos-mesh.org/docs/define-scheduling-rules/)と[`Workflow`](https://chaos-mesh.org/docs/create-chaos-mesh-workflow/)機能を提供します。設定された`Cron`時間に基づいて、`Schedule`は定期的かつ間隔を空けて障害をトリガーできます。`Workflow`はArgo Workflowsのように複数の障害テストをスケジュールできます。"
      }
    },
    {
      "segment_id": "dd65b89b",
      "source_content": "Chaos Controller Manager does most of the work for us. The control plane mainly manages these YAML resources. You only need to consider the features you want to provide to end users.",
      "source_content_hash": "038dbdc3f4f42492e95bab7e2f057a5f66952a279a701f2c29a4242c23fe34d9",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Chaos Controller Managerが大部分の作業を行ってくれます。コントロールプレーンは主にこれらのYAMLリソースを管理します。エンドユーザーに提供したい機能だけを考慮すればよいのです。"
      }
    },
    {
      "segment_id": "d8336f3e",
      "source_content": "### Platform features",
      "source_content_hash": "6af2ada91fd33d7d698a1c59dbf7e7caec89425c4af30ed455fbf809e1cd0011",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "### プラットフォーム機能"
      }
    },
    {
      "segment_id": "09fde125",
      "source_content": "The following figure shows Chaos Mesh Dashboard. We need to consider what features the platform should provide to end users.",
      "source_content_hash": "d92557a97d454520492765845960dd893c78f08d1fa25f6594bdd31269ec494a",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "以下の図はChaos Meshダッシュボードを示しています。エンドユーザーに提供すべき機能を考慮する必要があります。"
      }
    },
    {
      "segment_id": "36ecfe62",
      "source_content": "![Chaos Mesh Dashboard](/img/blog/chaos-mesh-dashboard-k8s.png)",
      "source_content_hash": "fa07a09a63fd361f9f516f1838913e64a62b2d4e1e4ac9e18d344ff4b3abf889",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "![Chaos Meshダッシュボード](/img/blog/chaos-mesh-dashboard-k8s.png)"
      }
    },
    {
      "segment_id": "db40fdec",
      "source_content": "From the Dashboard, we know that the platform may have these features:",
      "source_content_hash": "afa6bf4a725ca313ca2133ee468061ebe3101b1e3e412756f9c9bc75d522e745",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "ダッシュボードから、プラットフォームには以下の機能があることがわかります："
      }
    },
    {
      "segment_id": "f12e4485",
      "source_content": "- Chaos injection\n- Pod crash\n- Network failure\n- Load test\n- I/O failure\n- Event tracking\n- Associated alarm\n- Timing telemetry",
      "source_content_hash": "cd931d5c0cda309953e47a6b43604878ee0ed5f538892ad680f303d61a67f2f6",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "- カオスインジェクション\n- Podクラッシュ\n- ネットワーク障害\n- 負荷テスト\n- I/O障害\n- イベント追跡\n- 関連アラーム\n- タイミングテレメトリー"
      }
    },
    {
      "segment_id": "96a98088",
      "source_content": "If you are interested in Chaos Mesh and would like to improve it, join its [Slack channel](https://slack.cncf.io/) (#project-chaos-mesh) or submit your pull requests or issues to its [GitHub repository](https://github.com/chaos-mesh/chaos-mesh).",
      "source_content_hash": "79bbe381e6aa52782cfa8893cd4d4f562556dab9abd12fd9aa9293707ed586fd",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Chaos Meshに興味があり、改善に貢献したい場合は、[Slackチャンネル](https://slack.cncf.io/)（#project-chaos-mesh）に参加するか、[GitHubリポジトリ](https://github.com/chaos-mesh/chaos-mesh)にプルリクエストやイシューを提出してください。"
      }
    }
  ],
  "target_i18n_subpath": "docusaurus-plugin-content-blog/2021-12-10-implement-chaos-engineering-in-k8s.md",
  "last_updated_timestamp": "2025-06-05T17:50:36.625612+00:00",
  "schema_version": "1.0",
  "translated_versions": {
    "ja": "ae13e1a4f80105f1621a2eb77d731ffca386b1bfcbe31124119923e2a7d4be3b"
  }
}